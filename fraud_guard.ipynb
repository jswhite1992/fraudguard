{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e49ea7-6a3d-4975-a29c-0e660290e121",
   "metadata": {},
   "source": [
    "# FraudGuard ML\n",
    "\n",
    "## Project Overview\n",
    "FraudGuard ML is an innovative, machine learning-driven project designed to detect and deter fraudulent credit card transactions. In an era where online transactions are increasingly becoming the norm, maintaining transactional integrity and security is paramount. FraudGuard ML contributes to this security by leveraging the power of machine learning to identify potentially fraudulent transactions.\n",
    "\n",
    "Utilizing Python, a popular language in the data science realm due to its simplicity and powerful libraries, this project combines several machine learning techniques using libraries such as Scikit-learn. Flask, a lightweight and versatile web framework in Python, is used to create an API for model deployment.\n",
    "\n",
    "The system is trained on a rich dataset consisting of both fraudulent and non-fraudulent transactions. The dataset provides the foundation for the learning model, as it captures crucial transaction characteristics, trends, and patterns that can potentially signal a fraudulent transaction.\n",
    "\n",
    "The application offers a blend of data analytics and predictive modeling techniques to not just identify but also to learn and adapt to evolving transaction patterns. This ensures the system stays effective and up-to-date in the ever-changing landscape of online transactions.\n",
    "\n",
    "## Project Steps\n",
    "\n",
    "### Step 1: Data Acquisition and Understanding\n",
    "The foundation of this project is a comprehensive dataset of credit card transactions. Our goal in this step is to find a dataset that includes both fraudulent and non-fraudulent transactions. Once the data is obtained, understanding the variables and their meanings is crucial for the subsequent analysis.\n",
    "\n",
    "### Step 2: Exploratory Data Analysis (EDA) and Preprocessing\n",
    "We begin by analyzing the dataset using various EDA techniques to understand the data's structure, characteristics, and hidden patterns. This phase includes cleaning the data, managing missing values and outliers, and addressing class imbalance issues commonly found in fraud detection scenarios.\n",
    "\n",
    "### Step 3: Flask API Structure\n",
    "Simultaneously, we start setting up the basic structure of the Flask API. This step involves creating the necessary endpoints that will interact with our machine learning model. Although the model isn't ready yet, setting up the API structure early on paves the way for smooth integration later.\n",
    "\n",
    "### Step 4: Feature Selection and Engineering\n",
    "Once the data is preprocessed, we move on to the feature selection and engineering stage. This involves determining which variables or features are most relevant to our machine learning model. New features can also be created from existing ones to improve the model's performance.\n",
    "\n",
    "### Step 5: Model Building and Evaluation\n",
    "With the relevant features identified, we start building the machine learning model. This process involves training the model on our dataset and tuning it to best capture the patterns within the data. Subsequently, we evaluate the model using various metrics to ensure its accuracy and reliability in identifying fraudulent transactions.\n",
    "\n",
    "### Step 6: Flask API and Model Integration\n",
    "Upon successful model training and evaluation, we integrate the model with our previously set up Flask API. This allows the model to receive input data through the API, process it, and return predictions indicating whether a given transaction is likely to be fraudulent.\n",
    "\n",
    "### Step 7: Testing and Documentation\n",
    "This final phase involves rigorous testing of all parts of the project. From the machine learning model's prediction accuracy to the Flask API's performance, all components are put through thorough testing to ensure they work as expected. The project's documentation is completed in this step, detailing the methods, findings, and functionality of the system for transparency and replicability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed04787-9382-46f2-b3b8-54024e4cb1c0",
   "metadata": {},
   "source": [
    "### Step 1: Data Acquisition and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c96f82e-c725-423e-88bc-615b2e6df023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "# EPreprocessing/EDA\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Resample \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Fine Tune\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc856f53-e553-4894-8efb-1125f5e0836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows all the columns\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "# Set the float values to decimal points\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b609bf0f-2ec5-4855-b8fe-1789b702e3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>2.35</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time    V1    V2   V3    V4    V5    V6    V7    V8    V9   V10   V11  \\\n",
       "0  0.00 -1.36 -0.07 2.54  1.38 -0.34  0.46  0.24  0.10  0.36  0.09 -0.55   \n",
       "1  0.00  1.19  0.27 0.17  0.45  0.06 -0.08 -0.08  0.09 -0.26 -0.17  1.61   \n",
       "2  1.00 -1.36 -1.34 1.77  0.38 -0.50  1.80  0.79  0.25 -1.51  0.21  0.62   \n",
       "3  1.00 -0.97 -0.19 1.79 -0.86 -0.01  1.25  0.24  0.38 -1.39 -0.05 -0.23   \n",
       "4  2.00 -1.16  0.88 1.55  0.40 -0.41  0.10  0.59 -0.27  0.82  0.75 -0.82   \n",
       "\n",
       "    V12   V13   V14   V15   V16   V17   V18   V19   V20   V21   V22   V23  \\\n",
       "0 -0.62 -0.99 -0.31  1.47 -0.47  0.21  0.03  0.40  0.25 -0.02  0.28 -0.11   \n",
       "1  1.07  0.49 -0.14  0.64  0.46 -0.11 -0.18 -0.15 -0.07 -0.23 -0.64  0.10   \n",
       "2  0.07  0.72 -0.17  2.35 -2.89  1.11 -0.12 -2.26  0.52  0.25  0.77  0.91   \n",
       "3  0.18  0.51 -0.29 -0.63 -1.06 -0.68  1.97 -1.23 -0.21 -0.11  0.01 -0.19   \n",
       "4  0.54  1.35 -1.12  0.18 -0.45 -0.24 -0.04  0.80  0.41 -0.01  0.80 -0.14   \n",
       "\n",
       "    V24   V25   V26   V27   V28  Amount  Class  \n",
       "0  0.07  0.13 -0.19  0.13 -0.02  149.62      0  \n",
       "1 -0.34  0.17  0.13 -0.01  0.01    2.69      0  \n",
       "2 -0.69 -0.33 -0.14 -0.06 -0.06  378.66      0  \n",
       "3 -1.18  0.65 -0.22  0.06  0.06  123.50      0  \n",
       "4  0.14 -0.21  0.50  0.22  0.22   69.99      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179548</th>\n",
       "      <td>124130.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-1.78</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.96</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.66</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179549</th>\n",
       "      <td>124130.00</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>1.19</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>34.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179550</th>\n",
       "      <td>124130.00</td>\n",
       "      <td>2.04</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179551</th>\n",
       "      <td>124131.00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>144.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179552</th>\n",
       "      <td>124131.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>2.07</td>\n",
       "      <td>-2.47</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>1.78</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.81</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-1.02</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.14</td>\n",
       "      <td>50.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time    V1    V2    V3    V4    V5    V6    V7    V8    V9   V10  \\\n",
       "179548 124130.00  2.12 -0.09 -1.78  0.09  0.54 -0.48  0.13 -0.20  0.73  0.02   \n",
       "179549 124130.00 -0.71  0.46  0.20 -0.42  1.19 -1.34  0.83 -0.16  0.08 -1.70   \n",
       "179550 124130.00  2.04 -0.06 -1.16  0.22  0.13 -0.69  0.12 -0.21  0.20  0.22   \n",
       "179551 124131.00  1.83 -0.08 -2.25  1.18  0.83 -0.86  0.95 -0.46 -0.15  0.31   \n",
       "179552 124131.00 -1.00 -0.13  2.07 -2.47 -0.13 -0.10 -0.16  0.15 -1.02 -0.28   \n",
       "\n",
       "         V11   V12   V13   V14   V15   V16   V17   V18   V19   V20   V21  \\\n",
       "179548 -1.41 -0.31 -0.45  0.57  0.96 -0.01 -0.69  0.19 -0.02 -0.24  0.19   \n",
       "179549 -0.59  0.08  0.05 -1.70 -0.47 -0.11  1.17  0.16  0.00  0.12 -0.10   \n",
       "179550  0.79  1.40  0.75  0.31 -0.72  0.15 -0.70 -0.36  0.55 -0.16 -0.25   \n",
       "179551 -1.06  0.00 -0.06  0.82  0.27 -0.28 -0.57 -0.25 -0.30  0.03  0.18   \n",
       "179552 -0.64 -0.23  1.78 -0.98  0.37  1.81 -0.51 -1.02 -0.40  0.50  0.27   \n",
       "\n",
       "         V22   V23   V24   V25   V26   V27   V28  Amount  Class  \n",
       "179548  0.66 -0.04  0.04  0.34 -0.09 -0.03 -0.06    3.00      0  \n",
       "179549 -0.29 -0.04 -0.16 -0.16 -0.12  0.12  0.20   34.66      0  \n",
       "179550 -0.59  0.28 -0.32 -0.26  0.20 -0.07 -0.07    1.98      0  \n",
       "179551  0.28 -0.14  0.48  0.48 -0.52 -0.06 -0.04  144.00      0  \n",
       "179552  0.59 -0.19  0.63  0.55 -0.26  0.26  0.14   50.35      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in the fraudTrainlarge.csv file into a Pandas DataFrame\n",
    "transaction_fraud_data = pd.read_csv(\n",
    "    Path('./Resources/creditcard3.csv')\n",
    ")\n",
    "\n",
    "# Review DataFrame\n",
    "display(transaction_fraud_data.head())\n",
    "print('--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "display(transaction_fraud_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc4410ca-9ede-4f0c-b126-5177a77e3168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179553 entries, 0 to 179552\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    179553 non-null  float64\n",
      " 1   V1      179553 non-null  float64\n",
      " 2   V2      179553 non-null  float64\n",
      " 3   V3      179553 non-null  float64\n",
      " 4   V4      179553 non-null  float64\n",
      " 5   V5      179553 non-null  float64\n",
      " 6   V6      179553 non-null  float64\n",
      " 7   V7      179553 non-null  float64\n",
      " 8   V8      179553 non-null  float64\n",
      " 9   V9      179553 non-null  float64\n",
      " 10  V10     179553 non-null  float64\n",
      " 11  V11     179553 non-null  float64\n",
      " 12  V12     179553 non-null  float64\n",
      " 13  V13     179553 non-null  float64\n",
      " 14  V14     179553 non-null  float64\n",
      " 15  V15     179553 non-null  float64\n",
      " 16  V16     179553 non-null  float64\n",
      " 17  V17     179553 non-null  float64\n",
      " 18  V18     179553 non-null  float64\n",
      " 19  V19     179553 non-null  float64\n",
      " 20  V20     179553 non-null  float64\n",
      " 21  V21     179553 non-null  float64\n",
      " 22  V22     179553 non-null  float64\n",
      " 23  V23     179553 non-null  float64\n",
      " 24  V24     179553 non-null  float64\n",
      " 25  V25     179553 non-null  float64\n",
      " 26  V26     179553 non-null  float64\n",
      " 27  V27     179553 non-null  float64\n",
      " 28  V28     179553 non-null  float64\n",
      " 29  Amount  179553 non-null  float64\n",
      " 30  Class   179553 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 42.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(179553, 31)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check DataFrame data information\n",
    "display(transaction_fraud_data.info())\n",
    "print('Duplicates:')\n",
    "display(transaction_fraud_data.duplicated().sum())\n",
    "print('Null Values:')\n",
    "display(transaction_fraud_data.isnull().sum())\n",
    "print('Shape')\n",
    "display(transaction_fraud_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ebeb60-8c1e-4083-98f6-04d72b41db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the non-fraud transactions, fraud transactions and percentage of fraud transactions\n",
    "\n",
    "fraud = len(transaction_fraud_data[transaction_fraud_data.Class == 0])\n",
    "non_fraud = len(transaction_fraud_data[transaction_fraud_data.Class == 1])\n",
    "fraud_percent = (fraud / (fraud + non_fraud)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbf1e8cc-6def-4f11-92a8-fe4f9004d2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the \"Labels\" column in our dataset\n",
    "\n",
    "labels = [\"Non-Fraud\", \"Fraud\"]\n",
    "count_classes = transaction_fraud_data.value_counts(transaction_fraud_data['Class'], sort= True)\n",
    "count_classes.plot(kind = \"bar\", rot = 0)\n",
    "plt.title(\"Visualization of Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(range(2), labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354fd0f0-d3cf-45d9-a0fc-210922a8024f",
   "metadata": {},
   "source": [
    "### Step 2: Exploratory Data Analysis (EDA) and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "773f6bdb-eb39-417b-ac57-1550d7ac7a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      float64\n",
       "V1        float64\n",
       "V2        float64\n",
       "V3        float64\n",
       "V4        float64\n",
       "V5        float64\n",
       "V6        float64\n",
       "V7        float64\n",
       "V8        float64\n",
       "V9        float64\n",
       "V10       float64\n",
       "V11       float64\n",
       "V12       float64\n",
       "V13       float64\n",
       "V14       float64\n",
       "V15       float64\n",
       "V16       float64\n",
       "V17       float64\n",
       "V18       float64\n",
       "V19       float64\n",
       "V20       float64\n",
       "V21       float64\n",
       "V22       float64\n",
       "V23       float64\n",
       "V24       float64\n",
       "V25       float64\n",
       "V26       float64\n",
       "V27       float64\n",
       "V28       float64\n",
       "Amount    float64\n",
       "Class       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_fraud_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252f36dc-8a53-43ae-a829-a2158e614827",
   "metadata": {},
   "source": [
    "### Step 4: Feature Selection and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03223675-b1b8-4aaa-85a5-a926e84652fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "195177    0\n",
       "195178    0\n",
       "195179    0\n",
       "195180    0\n",
       "195181    0\n",
       "Name: Class, Length: 195182, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = transaction_fraud_data['Class']\n",
    "\n",
    "X = transaction_fraud_data.drop(columns=['Class'], axis=1)\n",
    "                    \n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbf38bbd-a2b0-4973-b6d7-e556d6199444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>2.54</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-1.34</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>2.35</td>\n",
       "      <td>-2.89</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>1.79</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>1.97</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.65</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.00</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195177</th>\n",
       "      <td>130932.00</td>\n",
       "      <td>2.03</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>19.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195178</th>\n",
       "      <td>130933.00</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>1.39</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>45.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195179</th>\n",
       "      <td>130933.00</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.84</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>124.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195180</th>\n",
       "      <td>130933.00</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>297.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195181</th>\n",
       "      <td>130935.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.34</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.01</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>40.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195182 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time    V1    V2    V3    V4    V5    V6    V7    V8    V9   V10  \\\n",
       "0           0.00 -1.36 -0.07  2.54  1.38 -0.34  0.46  0.24  0.10  0.36  0.09   \n",
       "1           0.00  1.19  0.27  0.17  0.45  0.06 -0.08 -0.08  0.09 -0.26 -0.17   \n",
       "2           1.00 -1.36 -1.34  1.77  0.38 -0.50  1.80  0.79  0.25 -1.51  0.21   \n",
       "3           1.00 -0.97 -0.19  1.79 -0.86 -0.01  1.25  0.24  0.38 -1.39 -0.05   \n",
       "4           2.00 -1.16  0.88  1.55  0.40 -0.41  0.10  0.59 -0.27  0.82  0.75   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "195177 130932.00  2.03 -0.07 -1.13  0.48 -0.07 -1.10  0.15 -0.35  0.38  0.16   \n",
       "195178 130933.00 -0.73  1.39 -0.30 -0.57  0.78 -0.37  1.18 -0.55 -0.10  0.15   \n",
       "195179 130933.00  1.76 -1.00 -1.88 -0.49  1.66  3.84 -1.05  0.99  0.86  0.06   \n",
       "195180 130933.00 -1.64  0.29 -0.49 -0.38  0.02 -0.63  1.55  0.27 -0.24 -2.09   \n",
       "195181 130935.00  1.96 -0.49 -0.22  0.12 -0.44  0.38 -0.91  0.09  1.34 -0.18   \n",
       "\n",
       "         V11   V12   V13   V14   V15   V16   V17   V18   V19   V20   V21  \\\n",
       "0      -0.55 -0.62 -0.99 -0.31  1.47 -0.47  0.21  0.03  0.40  0.25 -0.02   \n",
       "1       1.61  1.07  0.49 -0.14  0.64  0.46 -0.11 -0.18 -0.15 -0.07 -0.23   \n",
       "2       0.62  0.07  0.72 -0.17  2.35 -2.89  1.11 -0.12 -2.26  0.52  0.25   \n",
       "3      -0.23  0.18  0.51 -0.29 -0.63 -1.06 -0.68  1.97 -1.23 -0.21 -0.11   \n",
       "4      -0.82  0.54  1.35 -1.12  0.18 -0.45 -0.24 -0.04  0.80  0.41 -0.01   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "195177 -0.62  0.44  0.58  0.29  0.69  0.07 -0.55 -0.36 -0.37 -0.16  0.16   \n",
       "195178  1.36 -0.13 -0.49 -1.19  0.15  0.38  0.20  1.02  0.18 -0.10  0.30   \n",
       "195179 -0.06  0.28  0.07  0.15  1.28  0.46 -0.76  0.02 -0.63  0.12  0.26   \n",
       "195180 -0.32  0.45  0.51 -1.48 -0.53  0.01  1.39  0.13 -0.31  0.76  0.04   \n",
       "195181 -1.18  0.87  2.01 -0.57  1.55  0.97 -1.33  0.76 -0.37  0.02  0.26   \n",
       "\n",
       "         V22   V23   V24   V25   V26   V27   V28  Amount  \n",
       "0       0.28 -0.11  0.07  0.13 -0.19  0.13 -0.02  149.62  \n",
       "1      -0.64  0.10 -0.34  0.17  0.13 -0.01  0.01    2.69  \n",
       "2       0.77  0.91 -0.69 -0.33 -0.14 -0.06 -0.06  378.66  \n",
       "3       0.01 -0.19 -1.18  0.65 -0.22  0.06  0.06  123.50  \n",
       "4       0.80 -0.14  0.14 -0.21  0.50  0.22  0.22   69.99  \n",
       "...      ...   ...   ...   ...   ...   ...   ...     ...  \n",
       "195177  0.56  0.09 -0.03 -0.01  0.39 -0.06 -0.06   19.70  \n",
       "195178  0.72 -0.37  0.72 -0.01  0.58 -1.11 -0.21   45.61  \n",
       "195179  0.51  0.12  0.75 -0.29  0.36 -0.02 -0.03  124.00  \n",
       "195180 -0.38  0.54  0.94  0.25 -0.14  0.14  0.12  297.74  \n",
       "195181  0.85  0.11  0.08 -0.24 -0.29  0.06 -0.01   40.87  \n",
       "\n",
       "[195182 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f68ce2-a00b-4d02-96ff-6939a45dd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, test_index in train_test_sss.split(X, y):\n",
    "    train_df = transaction_fraud_data.loc[train_index]\n",
    "    test_df = transaction_fraud_data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6b3092e-ec5c-47d3-a450-785505e66cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = train_df.drop(['Class'], axis=1)\n",
    "y_train_df = train_df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08ab9d0e-0845-40eb-85b8-0cdec65bce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index, val_index in train_val_sss.split(X_train_df, y_train_df):\n",
    "    train_df = transaction_fraud_data.loc[train_index]\n",
    "    val_df = transaction_fraud_data.loc[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f5298b6-641e-431c-8de1-620147f80e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89352</th>\n",
       "      <td>62537.00</td>\n",
       "      <td>-3.68</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>3.36</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>-7.33</td>\n",
       "      <td>-6.26</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>1.39</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-6.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16344</th>\n",
       "      <td>27731.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>33.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122010</th>\n",
       "      <td>76401.00</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.85</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>1.94</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>17.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89917</th>\n",
       "      <td>62786.00</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-1.44</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>35.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79107</th>\n",
       "      <td>57869.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.33</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>0.88</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.02</td>\n",
       "      <td>84.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time    V1    V2    V3    V4    V5    V6    V7    V8    V9   V10  \\\n",
       "89352  62537.00 -3.68  1.85 -0.07 -0.53  3.36 -2.92 -7.33 -6.26  0.93  0.56   \n",
       "16344  27731.00  1.10 -0.04  0.49  0.56 -0.44 -0.29 -0.16  0.10 -0.07  0.08   \n",
       "122010 76401.00 -1.53  0.28 -0.21 -0.73  1.40  3.85 -1.23  1.94 -0.02 -0.95   \n",
       "89917  62786.00 -1.35 -0.73  0.93 -1.44 -0.16 -1.16 -0.62  0.54 -1.17 -0.21   \n",
       "79107  57869.00  0.98 -0.55  0.01  0.15  0.16  1.33 -0.33  0.45 -1.48  0.75   \n",
       "\n",
       "         V11   V12   V13  V14   V15   V16   V17   V18   V19   V20   V21   V22  \\\n",
       "89352  -1.18  0.95 -1.74 1.39 -0.54  0.05  0.60 -0.88 -0.90  0.82 -1.04 -0.65   \n",
       "16344   1.67  0.71 -0.68 0.62  0.61  0.12 -0.26 -0.26 -0.35 -0.11  0.04  0.03   \n",
       "122010 -1.00  0.28  0.08 0.26  0.08  0.63 -0.35  0.48  0.51 -0.16  0.07 -0.07   \n",
       "89917  -0.74 -1.41 -1.47 0.44  0.44  1.17  0.53 -1.46 -0.43  0.11  0.42  0.52   \n",
       "79107   2.09  0.89 -0.23 0.77  1.06 -2.56  0.88 -0.73 -2.14 -0.54 -0.54 -1.19   \n",
       "\n",
       "         V23   V24   V25   V26   V27   V28  Amount  Class  \n",
       "89352  -6.88  0.76 -2.30  0.60  0.41  0.16    2.00      0  \n",
       "16344   0.03  0.25  0.23  0.30 -0.03  0.01   33.49      0  \n",
       "122010  0.21  1.04 -0.36  0.22 -0.13 -0.15   17.07      0  \n",
       "89917   0.02  0.05 -0.36 -0.40  0.01 -0.07   35.00      0  \n",
       "79107   0.28 -1.12 -0.09 -0.64  0.08  0.02   84.29      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2334a645-6287-45fe-be90-a4d89eb91f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb25b0e0-ff20-425c-ac2b-985e250763b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124916 entries, 89352 to 28195\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    124916 non-null  float64\n",
      " 1   V1      124916 non-null  float64\n",
      " 2   V2      124916 non-null  float64\n",
      " 3   V3      124916 non-null  float64\n",
      " 4   V4      124916 non-null  float64\n",
      " 5   V5      124916 non-null  float64\n",
      " 6   V6      124916 non-null  float64\n",
      " 7   V7      124916 non-null  float64\n",
      " 8   V8      124916 non-null  float64\n",
      " 9   V9      124916 non-null  float64\n",
      " 10  V10     124916 non-null  float64\n",
      " 11  V11     124916 non-null  float64\n",
      " 12  V12     124916 non-null  float64\n",
      " 13  V13     124916 non-null  float64\n",
      " 14  V14     124916 non-null  float64\n",
      " 15  V15     124916 non-null  float64\n",
      " 16  V16     124916 non-null  float64\n",
      " 17  V17     124916 non-null  float64\n",
      " 18  V18     124916 non-null  float64\n",
      " 19  V19     124916 non-null  float64\n",
      " 20  V20     124916 non-null  float64\n",
      " 21  V21     124916 non-null  float64\n",
      " 22  V22     124916 non-null  float64\n",
      " 23  V23     124916 non-null  float64\n",
      " 24  V24     124916 non-null  float64\n",
      " 25  V25     124916 non-null  float64\n",
      " 26  V26     124916 non-null  float64\n",
      " 27  V27     124916 non-null  float64\n",
      " 28  V28     124916 non-null  float64\n",
      " 29  Amount  124916 non-null  float64\n",
      " 30  Class   124916 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 30.5 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "203f5d05-d353-4bc0-9ed5-70df12d16047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>69127.06</td>\n",
       "      <td>33663.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43788.00</td>\n",
       "      <td>66285.50</td>\n",
       "      <td>87657.25</td>\n",
       "      <td>130935.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>1.89</td>\n",
       "      <td>-56.41</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.62</td>\n",
       "      <td>-72.72</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.78</td>\n",
       "      <td>22.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.44</td>\n",
       "      <td>-33.68</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.23</td>\n",
       "      <td>9.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.90</td>\n",
       "      <td>16.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1.36</td>\n",
       "      <td>-42.15</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>34.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-26.16</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>22.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-43.56</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.49</td>\n",
       "      <td>36.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.21</td>\n",
       "      <td>-73.22</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.34</td>\n",
       "      <td>20.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.14</td>\n",
       "      <td>-13.43</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.63</td>\n",
       "      <td>15.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-24.59</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.44</td>\n",
       "      <td>23.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.92</td>\n",
       "      <td>12.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-18.68</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.61</td>\n",
       "      <td>7.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-5.79</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-19.21</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.51</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.95</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-14.13</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-25.16</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.42</td>\n",
       "      <td>9.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-9.50</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-7.21</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.47</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.75</td>\n",
       "      <td>-22.84</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.74</td>\n",
       "      <td>-34.83</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.15</td>\n",
       "      <td>27.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-10.93</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-44.81</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-2.84</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.42</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-10.30</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-22.57</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>12.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-11.71</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>33.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>89.51</td>\n",
       "      <td>248.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.99</td>\n",
       "      <td>22.93</td>\n",
       "      <td>79.00</td>\n",
       "      <td>19656.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>195182.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count     mean      std    min      25%      50%      75%       max\n",
       "Time   195182.00 69127.06 33663.41   0.00 43788.00 66285.50 87657.25 130935.00\n",
       "V1     195182.00    -0.11     1.89 -56.41    -0.96    -0.10     1.21      2.45\n",
       "V2     195182.00     0.01     1.62 -72.72    -0.58     0.08     0.78     22.06\n",
       "V3     195182.00     0.34     1.44 -33.68    -0.30     0.51     1.23      9.38\n",
       "V4     195182.00     0.08     1.40  -5.68    -0.79     0.08     0.90     16.88\n",
       "V5     195182.00    -0.12     1.36 -42.15    -0.79    -0.18     0.45     34.80\n",
       "V6     195182.00     0.05     1.31 -26.16    -0.71    -0.22     0.45     22.53\n",
       "V7     195182.00    -0.06     1.21 -43.56    -0.58    -0.01     0.49     36.68\n",
       "V8     195182.00     0.02     1.21 -73.22    -0.18     0.04     0.34     20.01\n",
       "V9     195182.00     0.01     1.14 -13.43    -0.66    -0.07     0.63     15.59\n",
       "V10    195182.00    -0.01     1.09 -24.59    -0.52    -0.10     0.44     23.75\n",
       "V11    195182.00     0.14     1.04  -4.80    -0.62     0.07     0.92     12.02\n",
       "V12    195182.00    -0.07     1.10 -18.68    -0.49     0.11     0.61      7.85\n",
       "V13    195182.00     0.04     1.03  -5.79    -0.64     0.01     0.71      4.57\n",
       "V14    195182.00     0.05     0.97 -19.21    -0.36     0.08     0.51     10.53\n",
       "V15    195182.00     0.09     0.95  -4.50    -0.50     0.18     0.78      5.78\n",
       "V16    195182.00    -0.01     0.89 -14.13    -0.48     0.06     0.53      6.10\n",
       "V17    195182.00     0.03     0.89 -25.16    -0.44    -0.03     0.42      9.25\n",
       "V18    195182.00    -0.04     0.84  -9.50    -0.52    -0.04     0.45      5.04\n",
       "V19    195182.00    -0.01     0.82  -7.21    -0.49    -0.01     0.47      5.59\n",
       "V20    195182.00     0.02     0.75 -22.84    -0.19    -0.04     0.15     39.42\n",
       "V21    195182.00    -0.02     0.74 -34.83    -0.23    -0.04     0.15     27.20\n",
       "V22    195182.00    -0.05     0.69 -10.93    -0.54    -0.04     0.42     10.50\n",
       "V23    195182.00    -0.02     0.61 -44.81    -0.17    -0.03     0.11     19.00\n",
       "V24    195182.00     0.00     0.60  -2.84    -0.34     0.05     0.42      4.02\n",
       "V25    195182.00     0.06     0.49 -10.30    -0.23     0.11     0.39      7.52\n",
       "V26    195182.00     0.01     0.49  -2.60    -0.33    -0.06     0.26      3.52\n",
       "V27    195182.00     0.00     0.39 -22.57    -0.07     0.01     0.09     12.15\n",
       "V28    195182.00     0.00     0.31 -11.71    -0.04     0.02     0.08     33.85\n",
       "Amount 195182.00    89.51   248.44   0.00     5.99    22.93    79.00  19656.53\n",
       "Class  195182.00     0.00     0.04   0.00     0.00     0.00     0.00      1.00"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transaction_fraud_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b4e6d-b6ed-4cf2-80e0-1f423fc721e3",
   "metadata": {},
   "source": [
    "As stated from the dataset author, the feature in the dataset is obtained from PCA. The only features that not obtained from PCA are 'Amount' and 'Time'. Standard scaler is required to apply on these two features. It is to avoid the model to have a false sense of feature 'Amount' and 'Time' is more significant than the rest of features when model being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c7531fa-ebbe-4a9d-b330-355cc4bcfb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   99.78\n",
       "1    0.22\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_weight_perc = train_df['Class'].value_counts(normalize=True) * 100\n",
    "\n",
    "label_weight_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc2cd62-6c72-41a6-82e1-0b8abb1cc6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V17      -0.42\n",
       "V14      -0.35\n",
       "V3       -0.30\n",
       "V12      -0.29\n",
       "V10      -0.29\n",
       "V7       -0.27\n",
       "V16      -0.26\n",
       "V18      -0.16\n",
       "V1       -0.15\n",
       "V5       -0.15\n",
       "V9       -0.12\n",
       "V6       -0.05\n",
       "V15      -0.01\n",
       "V13      -0.01\n",
       "V24      -0.01\n",
       "V25      -0.01\n",
       "V23      -0.00\n",
       "V26       0.00\n",
       "Time      0.00\n",
       "V28       0.00\n",
       "Amount    0.01\n",
       "V22       0.01\n",
       "V27       0.01\n",
       "V8        0.01\n",
       "V20       0.02\n",
       "V21       0.04\n",
       "V19       0.05\n",
       "V2        0.13\n",
       "V4        0.16\n",
       "V11       0.18\n",
       "Class     1.00\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()['Class'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aad3268-7ba0-44be-8e37-fe193edb46ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=train_df, y='Amount')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87bd74f2-1f0a-468c-88b9-632e49d16ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_outlier = dict()\n",
    "\n",
    "class Outlier:\n",
    "    def __init__(self, q1, q3):\n",
    "        self.q1 = q1\n",
    "        self.q3 = q3\n",
    "        self.iqr = q3 - q1\n",
    "    \n",
    "    def get_outlier_boundary(self):\n",
    "        lower_fence = self.q1 - 1.5 * self.iqr\n",
    "        upper_fence = self.q3 + 1.5 * self.iqr\n",
    "        \n",
    "        return lower_fence, upper_fence\n",
    "\n",
    "\n",
    "def filter_outlier(df, cols=[]):\n",
    "    if 'is_outlier' not in df.columns:\n",
    "        df['is_outlier'] = (False) * len(df)\n",
    "        \n",
    "    for col in cols:\n",
    "        if col in feature_outlier.keys():\n",
    "            outlier = feature_outlier[col]\n",
    "        else:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            \n",
    "            outlier = Outlier(q1, q3)\n",
    "            feature_outlier[col] = outlier\n",
    "             \n",
    "        lower_fence, upper_fence = outlier.get_outlier_boundary()\n",
    "        \n",
    "        outlier = (df[col] < lower_fence) | (df[col] > upper_fence)\n",
    "        \n",
    "        df['is_outlier'] = outlier | df['is_outlier']\n",
    "        \n",
    "    df = df[~df['is_outlier']]\n",
    "    df = df.drop(['is_outlier'], axis=1)\n",
    "             \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6540e304-4baa-4859-ba6a-96b25e79a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = filter_outlier(train_df, cols=['Amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba5eebc4-140d-4e53-bbd1-73b18f393790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standardisation to the feature 'city_pop'\n",
    "std_feat = ['Amount', 'Time']\n",
    "std_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7718a9b3-9c67-4694-af2e-97de4fb8d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    ('std_feat', std_pipeline, std_feat)\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bd11c68-cc29-4d5c-a63d-2e839aff79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(['Class'], axis=1)\n",
    "y_train = train_df['Class']\n",
    "\n",
    "X_train = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc765d77-7418-4120-8649-597f4fcc1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = val_df.drop(['Class'], axis=1)\n",
    "y_val = val_df['Class']\n",
    "\n",
    "X_val = full_pipeline.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9525b103-192f-490d-bb5f-557a52344c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop(['Class'], axis=1)\n",
    "y_test = test_df['Class']\n",
    "\n",
    "X_test = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1acb533-8751-415f-ba6e-9daaf383fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation Metrics\n",
    "model_eval = {\n",
    "    'model': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "\n",
    "def add_model_eval(model, recall, f1_score):\n",
    "    model_eval['model'].append(model)\n",
    "    model_eval['recall'].append(f'{recall: .2f}')\n",
    "    model_eval['f1_score'].append(f'{f1_score: .2f}')\n",
    "    \n",
    "def view_models_eval(sort=False):\n",
    "    eval_df = pd.DataFrame(model_eval)\n",
    "    \n",
    "    if sort:\n",
    "        eval_df = eval_df.sort_values(by=['recall', 'f1_score'], ascending=[False, False])\n",
    "    \n",
    "    display(eval_df.style.hide_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49d892a6-329e-4b29-b672-eb095498f21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           31     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.70128D+04    |proj g|=  5.53270D+04\n",
      "\n",
      "At iterate   50    f=  4.43255D+02    |proj g|=  1.44281D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   31     97    113      1     0     0   3.128D-02   4.431D+02\n",
      "  F =   443.13853487861684     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42, verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark Model - Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, verbose=1)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b492232e-6d28-4c94-a5fa-3b4bd0a4dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_val)\n",
    "\n",
    "add_model_eval('logistic regression', recall_score(y_val, y_pred), f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b6944f3-0a6c-4926-a39d-135e559f6d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_912ac_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >model</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_912ac_row0_col0\" class=\"data row0 col0\" >logistic regression</td>\n",
       "      <td id=\"T_912ac_row0_col1\" class=\"data row0 col1\" > 0.56</td>\n",
       "      <td id=\"T_912ac_row0_col2\" class=\"data row0 col2\" > 0.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc8a61d3d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_models_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a425763-8736-403e-86ea-2705e9258292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 19.67, NNZs: 30, Bias: -231.877763, T: 111106, Avg. loss: 0.360798\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 21.02, NNZs: 30, Bias: -227.313997, T: 222212, Avg. loss: 0.123056\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 23.84, NNZs: 30, Bias: -224.505351, T: 333318, Avg. loss: 0.109703\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 21.92, NNZs: 30, Bias: -222.791100, T: 444424, Avg. loss: 0.107929\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 21.94, NNZs: 30, Bias: -221.306461, T: 555530, Avg. loss: 0.107776\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 21.73, NNZs: 30, Bias: -220.124233, T: 666636, Avg. loss: 0.103749\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 21.36, NNZs: 30, Bias: -219.137358, T: 777742, Avg. loss: 0.104543\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 21.76, NNZs: 30, Bias: -218.213245, T: 888848, Avg. loss: 0.103922\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 21.70, NNZs: 30, Bias: -217.438510, T: 999954, Avg. loss: 0.102257\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 21.71, NNZs: 30, Bias: -216.739606, T: 1111060, Avg. loss: 0.101902\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 21.75, NNZs: 30, Bias: -216.103900, T: 1222166, Avg. loss: 0.100140\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 21.55, NNZs: 30, Bias: -215.550323, T: 1333272, Avg. loss: 0.099842\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 21.29, NNZs: 30, Bias: -215.045857, T: 1444378, Avg. loss: 0.099574\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 21.53, NNZs: 30, Bias: -214.532762, T: 1555484, Avg. loss: 0.099466\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 21.36, NNZs: 30, Bias: -214.092016, T: 1666590, Avg. loss: 0.099021\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 21.22, NNZs: 30, Bias: -213.679692, T: 1777696, Avg. loss: 0.099060\n",
      "Total training time: 0.22 seconds.\n",
      "Convergence after 16 epochs took 0.22 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(random_state=42, verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent (SGD) Classifier\n",
    "sgd_clf = SGDClassifier(random_state=42, verbose=1)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6af218fb-6d8b-4c8b-b1f8-2e6268cec191",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd_clf.predict(X_val)\n",
    "\n",
    "add_model_eval('sgd classifier', recall_score(y_val, y_pred), f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98d3bcf1-e6be-4fde-b54b-4e63549c9175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_7e77b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >model</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_7e77b_row0_col0\" class=\"data row0 col0\" >logistic regression</td>\n",
       "      <td id=\"T_7e77b_row0_col1\" class=\"data row0 col1\" > 0.56</td>\n",
       "      <td id=\"T_7e77b_row0_col2\" class=\"data row0 col2\" > 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_7e77b_row1_col0\" class=\"data row1 col0\" >sgd classifier</td>\n",
       "      <td id=\"T_7e77b_row1_col1\" class=\"data row1 col1\" > 0.53</td>\n",
       "      <td id=\"T_7e77b_row1_col2\" class=\"data row1 col2\" > 0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc8401cbd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_models_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d927631a-feb1-4c13-82e1-b550a96483ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   42.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42, verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "forest_clf = RandomForestClassifier(random_state=42, verbose=2)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d719756e-d8bb-4ec4-9bc4-5576a0d5e7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = forest_clf.predict(X_val)\n",
    "\n",
    "add_model_eval('random forest classifier', recall_score(y_val, y_pred), f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "780f3f0b-2dfc-4f8d-afae-ed34b0605b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2abc5_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >model</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2abc5_row0_col0\" class=\"data row0 col0\" >logistic regression</td>\n",
       "      <td id=\"T_2abc5_row0_col1\" class=\"data row0 col1\" > 0.56</td>\n",
       "      <td id=\"T_2abc5_row0_col2\" class=\"data row0 col2\" > 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2abc5_row1_col0\" class=\"data row1 col0\" >sgd classifier</td>\n",
       "      <td id=\"T_2abc5_row1_col1\" class=\"data row1 col1\" > 0.53</td>\n",
       "      <td id=\"T_2abc5_row1_col2\" class=\"data row1 col2\" > 0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2abc5_row2_col0\" class=\"data row2 col0\" >random forest classifier</td>\n",
       "      <td id=\"T_2abc5_row2_col1\" class=\"data row2 col1\" > 0.84</td>\n",
       "      <td id=\"T_2abc5_row2_col2\" class=\"data row2 col2\" > 0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc8a61d3510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_models_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96b24aeb-08f6-4276-ba84-f2ed19ef2716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM].\n",
      "Warning: using -h 0 may be faster\n",
      "*..*\n",
      "optimization finished, #iter = 3274\n",
      "obj = -186.407044, rho = -0.664919\n",
      "nSV = 1508, nBSV = 119\n",
      "Total nSV = 1508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(random_state=42, verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(random_state=42, verbose=2)\n",
    "svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3d03b84-fb1e-4563-bb9b-f27436be736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(X_val)\n",
    "\n",
    "add_model_eval('support vector machine classifier', recall_score(y_val, y_pred), f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ebed79d-2bbb-43f6-9ec0-b90a3c406897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f397d_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >model</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f397d_row0_col0\" class=\"data row0 col0\" >logistic regression</td>\n",
       "      <td id=\"T_f397d_row0_col1\" class=\"data row0 col1\" > 0.56</td>\n",
       "      <td id=\"T_f397d_row0_col2\" class=\"data row0 col2\" > 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f397d_row1_col0\" class=\"data row1 col0\" >sgd classifier</td>\n",
       "      <td id=\"T_f397d_row1_col1\" class=\"data row1 col1\" > 0.53</td>\n",
       "      <td id=\"T_f397d_row1_col2\" class=\"data row1 col2\" > 0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f397d_row2_col0\" class=\"data row2 col0\" >random forest classifier</td>\n",
       "      <td id=\"T_f397d_row2_col1\" class=\"data row2 col1\" > 0.84</td>\n",
       "      <td id=\"T_f397d_row2_col2\" class=\"data row2 col2\" > 0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f397d_row3_col0\" class=\"data row3 col0\" >support vector machine classifier</td>\n",
       "      <td id=\"T_f397d_row3_col1\" class=\"data row3 col1\" > 0.67</td>\n",
       "      <td id=\"T_f397d_row3_col2\" class=\"data row3 col2\" > 0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc8401bd6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_models_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71e471c5-c6c1-413f-8267-b7f149dbc223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "783337ff-39ad-433a-b8bf-7650cb8fe4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_clf.predict(X_val)\n",
    "\n",
    "add_model_eval('naive bayes', recall_score(y_val, y_pred), f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "00c05dc6-7874-4175-8a4a-ab885b059dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_efb28_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >model</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_efb28_row0_col0\" class=\"data row0 col0\" >logistic regression</td>\n",
       "      <td id=\"T_efb28_row0_col1\" class=\"data row0 col1\" > 0.56</td>\n",
       "      <td id=\"T_efb28_row0_col2\" class=\"data row0 col2\" > 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efb28_row1_col0\" class=\"data row1 col0\" >sgd classifier</td>\n",
       "      <td id=\"T_efb28_row1_col1\" class=\"data row1 col1\" > 0.53</td>\n",
       "      <td id=\"T_efb28_row1_col2\" class=\"data row1 col2\" > 0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efb28_row2_col0\" class=\"data row2 col0\" >random forest classifier</td>\n",
       "      <td id=\"T_efb28_row2_col1\" class=\"data row2 col1\" > 0.84</td>\n",
       "      <td id=\"T_efb28_row2_col2\" class=\"data row2 col2\" > 0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efb28_row3_col0\" class=\"data row3 col0\" >support vector machine classifier</td>\n",
       "      <td id=\"T_efb28_row3_col1\" class=\"data row3 col1\" > 0.67</td>\n",
       "      <td id=\"T_efb28_row3_col2\" class=\"data row3 col2\" > 0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_efb28_row4_col0\" class=\"data row4 col0\" >naive bayes</td>\n",
       "      <td id=\"T_efb28_row4_col1\" class=\"data row4 col1\" > 0.67</td>\n",
       "      <td id=\"T_efb28_row4_col2\" class=\"data row4 col2\" > 0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc8401c3090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_models_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65390191-5027-4464-8a1c-b6f070227eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4c836_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >model</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_4c836_row0_col0\" class=\"data row0 col0\" >random forest classifier</td>\n",
       "      <td id=\"T_4c836_row0_col1\" class=\"data row0 col1\" > 0.84</td>\n",
       "      <td id=\"T_4c836_row0_col2\" class=\"data row0 col2\" > 0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4c836_row1_col0\" class=\"data row1 col0\" >support vector machine classifier</td>\n",
       "      <td id=\"T_4c836_row1_col1\" class=\"data row1 col1\" > 0.67</td>\n",
       "      <td id=\"T_4c836_row1_col2\" class=\"data row1 col2\" > 0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4c836_row2_col0\" class=\"data row2 col0\" >naive bayes</td>\n",
       "      <td id=\"T_4c836_row2_col1\" class=\"data row2 col1\" > 0.67</td>\n",
       "      <td id=\"T_4c836_row2_col2\" class=\"data row2 col2\" > 0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4c836_row3_col0\" class=\"data row3 col0\" >logistic regression</td>\n",
       "      <td id=\"T_4c836_row3_col1\" class=\"data row3 col1\" > 0.56</td>\n",
       "      <td id=\"T_4c836_row3_col2\" class=\"data row3 col2\" > 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_4c836_row4_col0\" class=\"data row4 col0\" >sgd classifier</td>\n",
       "      <td id=\"T_4c836_row4_col1\" class=\"data row4 col1\" > 0.53</td>\n",
       "      <td id=\"T_4c836_row4_col2\" class=\"data row4 col2\" > 0.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc8a4d2fd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_models_eval(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "72bf4e6f-b18f-4ec8-9999-69bf8f371a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  54.0s\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=300; total time=  44.5s\n",
      "[CV] END bootstrap=False, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time= 1.8min\n",
      "[CV] END bootstrap=True, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=  59.8s\n",
      "[CV] END bootstrap=False, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  33.7s\n",
      "[CV] END bootstrap=False, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  18.2s\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  14.8s\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.5min\n",
      "[CV] END bootstrap=True, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time= 1.3min\n",
      "[CV] END bootstrap=True, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 1.2min\n",
      "[CV] END bootstrap=True, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 1.0min\n",
      "[CV] END bootstrap=False, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 2.3min\n",
      "[CV] END bootstrap=False, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time= 1.9min\n",
      "[CV] END bootstrap=False, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time= 2.2min\n",
      "[CV] END bootstrap=False, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time= 1.8min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=RandomForestClassifier(random_state=42),\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=42, scoring='recall', verbose=2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine Tune best performing model\n",
    "# clf = classifier\n",
    "# ft = fine-tune\n",
    "forest_clf_ft = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(forest_clf_ft, \n",
    "                                   param_grid, \n",
    "                                   random_state=42,\n",
    "                                   cv=2,\n",
    "                                   n_iter=10, \n",
    "                                   scoring='recall',\n",
    "                                   verbose=2)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "97516e3c-9a25-4c5d-880f-7f9ba2232d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf_best_params = random_search.best_params_\n",
    "\n",
    "forest_clf_best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a719682-8cb3-4eec-8aa0-8ad6a4eaee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_search.predict(X_val)\n",
    "\n",
    "add_model_eval('random forest classifier with fine-tune', recall_score(y_val, y_pred), f1_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "01cc0d8f-4914-4dc9-826e-e914fc902737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f7fc1_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >model</th>\n",
       "      <th class=\"col_heading level0 col1\" >recall</th>\n",
       "      <th class=\"col_heading level0 col2\" >f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f7fc1_row0_col0\" class=\"data row0 col0\" >logistic regression</td>\n",
       "      <td id=\"T_f7fc1_row0_col1\" class=\"data row0 col1\" > 0.56</td>\n",
       "      <td id=\"T_f7fc1_row0_col2\" class=\"data row0 col2\" > 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f7fc1_row1_col0\" class=\"data row1 col0\" >sgd classifier</td>\n",
       "      <td id=\"T_f7fc1_row1_col1\" class=\"data row1 col1\" > 0.53</td>\n",
       "      <td id=\"T_f7fc1_row1_col2\" class=\"data row1 col2\" > 0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f7fc1_row2_col0\" class=\"data row2 col0\" >random forest classifier</td>\n",
       "      <td id=\"T_f7fc1_row2_col1\" class=\"data row2 col1\" > 0.84</td>\n",
       "      <td id=\"T_f7fc1_row2_col2\" class=\"data row2 col2\" > 0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f7fc1_row3_col0\" class=\"data row3 col0\" >support vector machine classifier</td>\n",
       "      <td id=\"T_f7fc1_row3_col1\" class=\"data row3 col1\" > 0.67</td>\n",
       "      <td id=\"T_f7fc1_row3_col2\" class=\"data row3 col2\" > 0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f7fc1_row4_col0\" class=\"data row4 col0\" >naive bayes</td>\n",
       "      <td id=\"T_f7fc1_row4_col1\" class=\"data row4 col1\" > 0.67</td>\n",
       "      <td id=\"T_f7fc1_row4_col2\" class=\"data row4 col2\" > 0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f7fc1_row5_col0\" class=\"data row5 col0\" >random forest classifier with fine-tune</td>\n",
       "      <td id=\"T_f7fc1_row5_col1\" class=\"data row5 col1\" > 0.85</td>\n",
       "      <td id=\"T_f7fc1_row5_col2\" class=\"data row5 col2\" > 0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc8401d2510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_models_eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
